Epoch 1/4:  19%|█████████████▋                                                         | 29/150 [00:02<00:05, 23.53it/s]
当前学习率: 0.000491
⚠️  批次 0 检测到 NaN/Inf 损失，跳过此批次...
损失详情: {'total_loss_f': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>), 'pixel_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'gradient_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'perceptual_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'total_loss_vi': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'rec_n': tensor(5.5452, device='cuda:1'), 'kl_loss_n': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'total_loss': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>)}
⚠️  批次 1 内存不足，跳过...
⚠️  批次 2 内存不足，跳过...
⚠️  批次 3 内存不足，跳过...
⚠️  批次 4 内存不足，跳过...
⚠️  批次 5 内存不足，跳过...
⚠️  批次 6 内存不足，跳过...
⚠️  批次 7 内存不足，跳过...
⚠️  批次 8 内存不足，跳过...
⚠️  批次 9 内存不足，跳过...
⚠️  批次 10 内存不足，跳过...
⚠️  批次 11 内存不足，跳过...
⚠️  批次 12 内存不足，跳过...
⚠️  批次 13 内存不足，跳过...
⚠️  批次 14 内存不足，跳过...
⚠️  批次 15 内存不足，跳过...
⚠️  批次 16 内存不足，跳过...
⚠️  批次 17 内存不足，跳过...
⚠️  批次 18 内存不足，跳过...
⚠️  批次 19 内存不足，跳过...
⚠️  批次 20 内存不足，跳过...
⚠️  批次 21 内存不足，跳过...
⚠️  批次 22 内存不足，跳过...
⚠️  批次 23 内存不足，跳过...
⚠️  批次 24 内存不足，跳过...
⚠️  批次 25 内存不足，跳过...
⚠️  批次 26 内存不足，跳过...
⚠️  批次 27 内存不足，跳过...
⚠️  批次 28 内存不足，跳过...
⚠️  批次 29 内存不足，跳过...
⚠️  批次 30 内存不足，跳过...
⚠️  批次 31 内存不足，跳过...
⚠️  批次 32 内存不足，跳过...
⚠️  批次 33 内存不足，跳过...
⚠️  批次 34 内存不足，跳过...
⚠️  批次 35 内存不足，跳过...
⚠️  批次 36 内存不足，跳过...
⚠️  批次 37 内存不足，跳过...
⚠️  批次 38 内存不足，跳过...
⚠️  批次 39 内存不足，跳过...
⚠️  批次 40 内存不足，跳过...
⚠️  批次 41 内存不足，跳过...
⚠️  批次 42 内存不足，跳过...
⚠️  批次 43 内存不足，跳过...
⚠️  批次 44 内存不足，跳过...
⚠️  批次 45 内存不足，跳过...
⚠️  批次 46 内存不足，跳过...
⚠️  批次 47 内存不足，跳过...
⚠️  批次 48 内存不足，跳过...
⚠️  批次 49 内存不足，跳过...
⚠️  批次 50 内存不足，跳过...
⚠️  批次 51 内存不足，跳过...
⚠️  批次 52 内存不足，跳过...
⚠️  批次 53 内存不足，跳过...
⚠️  批次 54 内存不足，跳过...
⚠️  批次 55 内存不足，跳过...
⚠️  批次 56 内存不足，跳过...
⚠️  批次 57 内存不足，跳过...
Traceback (most recent call last):
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 122, in train_epoch_model
    Ic_image, n, mu_n, sigma2_n =model(d_image,device_1, device_2)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/model.py", line 38, in forward
    n,mu_n,sigma2_n = self.noise_encoder_decoder(image)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/model.py", line 22, in forward
    x=self.encoder(x)
      ^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/component.py", line 19, in forward
    x=self.model(x)
      ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 265, in forward
    out_dec_level1 = self.decoder_level1(inp_dec_level1)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 142, in forward
    x = x + self.ffn(self.norm2(x))
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 85, in forward
    x = F.gelu(x1) * x2
        ^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 23.53 GiB of which 31.06 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.63 GiB is allocated by PyTorch, and 402.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 570, in <module>
    main(**config_dic)
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 462, in main
    best_epoch, best_loss = train_model(
                            ^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 217, in train_model
    epoch_loss = train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, val_loader, pbar)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 163, in train_epoch_model
    if "out of memory" in str(e):
                          ^^^^^^
KeyboardInterrupt
