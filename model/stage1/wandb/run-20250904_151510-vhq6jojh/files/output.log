Epoch 1/3:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                         | 29/150 [00:02<00:05, 22.11it/s]
å½“å‰å­¦ä¹ ç‡: 0.000655
âš ï¸  æ‰¹æ¬¡ 0 æ£€æµ‹åˆ° NaN/Inf æŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡...
æŸå¤±è¯¦æƒ…: {'total_loss_f': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>), 'pixel_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'gradient_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'perceptual_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'total_loss_vi': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'rec_n': tensor(5.5452, device='cuda:1'), 'kl_loss_n': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'total_loss': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>)}
âš ï¸  æ‰¹æ¬¡ 1 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 2 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 3 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 4 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 5 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 6 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 7 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 8 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 9 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 10 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 11 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 12 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 13 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 14 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 15 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 16 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 17 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 18 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 19 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 20 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 21 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 22 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 23 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 24 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 25 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 26 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 27 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 28 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 29 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 30 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 31 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 32 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 33 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 34 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 35 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 36 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 37 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 38 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 39 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 40 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 41 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 42 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 43 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 44 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 45 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 46 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 47 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 48 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 49 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 50 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 51 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 52 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 53 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 54 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 55 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 56 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 57 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 58 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 59 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 60 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 61 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 62 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 63 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 64 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 65 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 66 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 67 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 68 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 69 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 70 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 71 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 72 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 73 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 74 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 75 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 76 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 77 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 78 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 79 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 80 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 81 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 82 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 83 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 84 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 85 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 86 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 87 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 88 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 89 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 90 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 91 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 92 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 93 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 94 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 95 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 96 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 97 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 98 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 99 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 100 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 101 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 102 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 103 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 104 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 105 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 106 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 107 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 108 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 109 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 110 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 111 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 112 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 113 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 114 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 115 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 116 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 117 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 118 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 119 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 120 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 121 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 122 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 123 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 124 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 125 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 126 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 127 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 128 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 129 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 130 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 131 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 132 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 133 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 134 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 135 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 136 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 137 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 138 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 139 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 140 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 141 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 142 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 143 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 144 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 145 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 146 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 147 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 148 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 149 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
âœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ (Epoch 1)
Epoch [1/3],Train Loss: 0.0000 ğŸ†
Epoch 2/3:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                   | 9/150 [00:01<00:26,  5.39it/s]
å½“å‰å­¦ä¹ ç‡: 0.000491
âš ï¸  æ‰¹æ¬¡ 0 æ£€æµ‹åˆ° NaN/Inf æŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡...
æŸå¤±è¯¦æƒ…: {'total_loss_f': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>), 'pixel_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'gradient_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'perceptual_loss': tensor(nan, device='cuda:1', grad_fn=<MeanBackward0>), 'total_loss_vi': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'rec_n': tensor(5.5452, device='cuda:1'), 'kl_loss_n': tensor(nan, device='cuda:1', grad_fn=<MulBackward0>), 'total_loss': tensor(nan, device='cuda:1', grad_fn=<AddBackward0>)}
âš ï¸  æ‰¹æ¬¡ 1 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 2 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 3 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 4 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 5 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 6 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 7 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
âš ï¸  æ‰¹æ¬¡ 8 å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...
Traceback (most recent call last):
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 122, in train_epoch_model
    Ic_image, n, mu_n, sigma2_n =model(d_image,device_1, device_2)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/model.py", line 37, in forward
    n,mu_n,sigma2_n = self.noise_encoder_decoder(image)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/model.py", line 22, in forward
    x=self.encoder(x)
      ^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/component.py", line 19, in forward
    x=self.model(x)
      ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 265, in forward
    out_dec_level1 = self.decoder_level1(inp_dec_level1)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 142, in forward
    x = x + self.ffn(self.norm2(x))
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/../restormer/restormer_arch.py", line 85, in forward
    x = F.gelu(x1) * x2
        ~~~~~~~~~~~^~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 23.53 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 361.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 570, in <module>
    main(**config_dic)
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 462, in main
    best_epoch, best_loss = train_model(
                            ^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 217, in train_model
    epoch_loss = train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, val_loader, pbar)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/1024_whs/IVfusion_method1/model/stage1/train_dc.py", line 163, in train_epoch_model
    if "out of memory" in str(e):
                          ^^^^^^
KeyboardInterrupt
