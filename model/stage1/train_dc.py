import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
import torch
from torch.utils.data import Dataset,DataLoader
from tqdm import tqdm
import wandb
import torch.nn as nn
from model import Degrad_restore_model
from loss import Loss
from data_process.dataset import ImageDataset
from PIL import Image
import math
import argparse
import torchvision.transforms as transforms
import yaml
import gc
from checkpoint_utils import (
    load_checkpoint_memory_efficient, 
    load_model_only, 
    save_checkpoint_compressed,
    get_checkpoint_info
)

class PairedDataset(Dataset):
        def __init__(self, i_dataset, v_dataset):
            assert len(i_dataset) == len(v_dataset), "ä¸¤ä¸ªæ•°æ®é›†é•¿åº¦å¿…é¡»ç›¸ç­‰"
            self.i_dataset = i_dataset
            self.v_dataset = v_dataset
        
        def __len__(self):
            return len(self.i_dataset)
        
        def __getitem__(self, idx):
            i_image= self.i_dataset[idx][0]
            v_image = self.v_dataset[idx][0]
            return i_image, v_image

def load_config(config_path, experiment=None):
    """
    åŠ è½½YAMLé…ç½®æ–‡ä»¶
    
    Args:
        config_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾„
        experiment: å®éªŒåç§°ï¼Œå¦‚æœæŒ‡å®šåˆ™ä¼šåˆå¹¶å¯¹åº”å®éªŒçš„é…ç½®
    
    Returns:
        config: é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as file:
        config = yaml.safe_load(file)
    
    # å¦‚æœæŒ‡å®šäº†å®éªŒåç§°ï¼Œåˆå¹¶å®éªŒé…ç½®
    if experiment and 'experiments' in config and experiment in config['experiments']:
        exp_config = config['experiments'][experiment]
        config = merge_configs(config, exp_config)
    
    return config

def merge_configs(base_config, override_config):
    """
    é€’å½’åˆå¹¶é…ç½®å­—å…¸
    """
    result = base_config.copy()
    
    for key, value in override_config.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = merge_configs(result[key], value)
        else:
            result[key] = value
    
    return result

def config_to_args(config):
    """
    å°†é…ç½®å­—å…¸è½¬æ¢ä¸ºå‚æ•°å­—å…¸ï¼Œç”¨äºä¼ é€’ç»™mainå‡½æ•°
    """
    args = {}
    
    # æ•°æ®é…ç½®
    if 'data' in config:
        args.update({
            'd_data_dir': config['data'].get('d_data_dir'),
            'c_data_dir': config['data'].get('c_data_dir'),
            'mode': config['data'].get('mode', 'L')
        })
    
    # è®­ç»ƒé…ç½®
    if 'training' in config:
        args.update({
            'project_name': config['training'].get('project_name'),
            'batch_size': config['training'].get('batch_size', 2),
            'num_epochs': config['training'].get('num_epochs', 5),
            'resume_from_checkpoint': config['training'].get('resume_from_checkpoint', False)
        })
    
    # è®¾å¤‡é…ç½®
    if 'device' in config:
        args.update({
            'device_1': config['device'].get('device_1', 'cuda:0'),
            'device_2': config['device'].get('device_2', 'cuda:1'),
            'device_3': config['device'].get('device_3', 'cuda:2')
        })
    
    # æ¨¡å‹é…ç½®
    if 'model' in config:
        args.update({
            'i_block_num': config['model'].get('i_block_num', 2),
            'v_block_num': config['model'].get('v_block_num', 2),
            'i_expert_num': config['model'].get('i_expert_num', 3),
            'v_expert_num': config['model'].get('v_expert_num', 3),
            'i_topk_expert': config['model'].get('i_topk_expert', 2),
            'v_topk_expert': config['model'].get('v_topk_expert', 2),
            'i_alpha': config['model'].get('i_alpha', 1.0),
            'v_alpha': config['model'].get('v_alpha', 1.0),
            'f_block_num': config['model'].get('f_block_num', 3)
        })
    
    # å†…å­˜ä¼˜åŒ–é…ç½®
    if 'memory' in config:
        args.update({
            'memory_efficient': config['memory'].get('checkpoint_memory_efficient', True),
            'load_optimizer_state': config['memory'].get('load_optimizer_state', True),
            'compress_checkpoints': config['memory'].get('compress_checkpoints', True),
            'save_optimizer_in_epoch_checkpoints': config['memory'].get('save_optimizer_in_epoch_checkpoints', False)
        })
    else:
        # é»˜è®¤å†…å­˜ä¼˜åŒ–è®¾ç½®
        args.update({
            'memory_efficient': True,
            'load_optimizer_state': True,
            'compress_checkpoints': True,
            'save_optimizer_in_epoch_checkpoints': False
        })
    
    return args
def train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, val_loader, pbar):
    model.train()
    running_loss = 0.0
    epoch_loss = 0.0
    
    # æ¸…ç†GPUç¼“å­˜
    torch.cuda.empty_cache()
    
    for batch_idx, (d_image, c_image) in enumerate(pbar):
        try:
            Ic_image, n, mu_n, sigma2_n =model(d_image,device_1, device_2)

            # è®¡ç®—æŸå¤±
            criterion=criterion.to(device_2)
            # å°†æ¨¡å‹è¾“å‡ºç§»åŠ¨åˆ°device_3
            d_image=d_image.to(device_2)
            c_image=c_image.to(device_2)
            Ic_image = Ic_image.to(device_2)
            n = n.to(device_2)
            mu_n = mu_n.to(device_2)
            sigma2_n = sigma2_n.to(device_2)
            torch.cuda.empty_cache()
            loss_all= criterion(Ic_image, d_image, c_image, n, mu_n, sigma2_n)
            del d_image,c_image,Ic_image,n,mu_n,sigma2_n
            loss=loss_all["total_loss"]
            
            # æ£€æµ‹ NaN å’Œ Inf
            if torch.isnan(loss) or torch.isinf(loss):
                print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} æ£€æµ‹åˆ° NaN/Inf æŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡...")
                print(f"æŸå¤±è¯¦æƒ…: {loss_all}")
                del loss_all
                torch.cuda.empty_cache()
                continue

            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            optimizer.zero_grad()
            wandb.log(loss_all)
            torch.cuda.empty_cache()
            
            # ç»Ÿè®¡æŸå¤±
            running_loss += loss.item()
            epoch_loss += loss.item()

                
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...")
                torch.cuda.empty_cache()
                continue
            else:
                raise e
                
    return epoch_loss
def train_model(model, train_loader, criterion, optimizer, device_1, device_2, project_name, num_epochs=10, val_loader=None, checkpoint_dir="./checkpoints"):
    """
    è®­ç»ƒå‡½æ•°ï¼Œé›†æˆwandbç›‘æ§å’Œæ£€æŸ¥ç‚¹ä¿å­˜
    
    Args:
        model: è®­ç»ƒæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        device_1, device_2, device_3: è®¾å¤‡
        num_epochs: è®­ç»ƒè½®æ•°
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        project_name: wandbé¡¹ç›®åç§°
        checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
    """
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # åˆå§‹åŒ–wandb
    wandb.init(project=project_name)
    
    # åˆå§‹åŒ–æœ€ä½³æ€§èƒ½æŒ‡æ ‡
    best_val_loss = float('inf')
    best_train_loss = float('inf') 
    best_epoch = 0
    
    model.train()
    
    for epoch in range(num_epochs):
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - éšç€è®­ç»ƒå‡å°å­¦ä¹ ç‡
        if epoch == 0:
            # åœ¨ç¬¬ä¸€ä¸ªepochåˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
            #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)
            # æˆ–è€…ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
            # æˆ–è€…ä½¿ç”¨æŒ‡æ•°è¡°å‡
            # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)

        # åœ¨æ¯ä¸ªepochç»“æŸåæ›´æ–°å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']
        print(f'å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}')
        
        # åœ¨æ¯ä¸ªepochç»“æŸåæ›´æ–°å­¦ä¹ ç‡
        epoch_loss = train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, val_loader, pbar)
        scheduler.step()
        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_loss = epoch_loss / len(train_loader)

        # éªŒè¯é˜¶æ®µ
        val_metrics = {}
        val_loss = None
        if val_loader is not None:
            val_loss, val_acc = validate_model(model, val_loader, criterion, device_1, device_2)
            val_metrics = {"val_loss": val_loss}
        
        # è®°å½•epochæŒ‡æ ‡åˆ°wandb
        wandb.log({
            "epoch": epoch + 1,
            "train_loss": avg_loss,
            **val_metrics
        })
        # ä¿å­˜å½“å‰epochæ£€æŸ¥ç‚¹
        # åˆ›å»ºæ£€æŸ¥ç‚¹å­—å…¸
        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': avg_loss,
            'val_loss': val_loss,
            **val_metrics
        }
        
        # ä½¿ç”¨å‹ç¼©ä¿å­˜å‡å°‘æ–‡ä»¶å¤§å°
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_checkpoint_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
        save_checkpoint_compressed(
            model, optimizer, epoch + 1, avg_loss, val_loss,
            latest_checkpoint_path, compress=True, save_optimizer=True
        )
        
        # ä¿å­˜æ¯ä¸ªepochçš„æ£€æŸ¥ç‚¹ï¼ˆå¯é€‰æ‹©ä¸ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€ä»¥èŠ‚çœç©ºé—´ï¼‰
        epoch_checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')
        save_checkpoint_compressed(
            model, optimizer, epoch + 1, avg_loss, val_loss,
            epoch_checkpoint_path, compress=True, save_optimizer=False  # ä¸ä¿å­˜ä¼˜åŒ–å™¨å‡å°‘æ–‡ä»¶å¤§å°
        )
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        is_best = False
        current_metric = val_loss if val_loss is not None else avg_loss
        best_metric = best_val_loss if val_loss is not None else best_train_loss
        
        if current_metric < best_metric:
            is_best = True
            if val_loss is not None:
                best_val_loss = val_loss
            else:
                best_train_loss = avg_loss
            best_epoch = epoch + 1
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹ - ä½¿ç”¨å‹ç¼©ä¿å­˜
            best_checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')
            save_checkpoint_compressed(
                model, None, epoch + 1, avg_loss, val_loss,  # ä¸ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
                best_checkpoint_path, compress=True, save_optimizer=False
            )
            print(f"âœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ (Epoch {epoch+1})")
        
        # æ¸…ç†å†…å­˜
        del checkpoint
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        # æ‰“å°epochæŸå¤±
        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_loss:.4f}' + 
              (f', Val Loss: {val_metrics.get("val_loss", 0):.4f}, Val Acc: {val_metrics.get("val_accuracy", 0):.4f}' if val_metrics else '') +
              (f' {"ğŸ†" if is_best else ""}'))
    
    print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹æ¥è‡ª Epoch {best_epoch}")
    print(f"æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„: {checkpoint_dir}")
    return best_epoch, best_val_loss if val_loader else best_train_loss

def validate_model(model, val_loader, criterion, device_1, device_2, device_3):
    """
    éªŒè¯å‡½æ•°
    """
    model.eval()
    val_loss = 0.0
    
    with torch.no_grad():
        for i,v in tqdm(val_loader, desc='Validating'):
            output,l, g, mu_l, sigma2_l, mu_g, sigma2_g= model(i,v, device_1, device_2, device_3)
            loss_all= criterion(output, i,v, l, g, mu_l, sigma2_l, mu_g, sigma2_g)
            val_loss=loss_all["total_loss"]
            
    model.train()
    return val_loss / len(val_loader)


def load_checkpoint(model, optimizer, checkpoint_path, memory_efficient=True, load_optimizer=True):
    """
    åŠ è½½æ£€æŸ¥ç‚¹ - æ”¯æŒå†…å­˜ä¼˜åŒ–
    """
    if memory_efficient:  # ä¿®å¤é€»è¾‘é”™è¯¯
        # å†…å­˜é«˜æ•ˆçš„åŠ è½½æ–¹å¼
        print(f"æ­£åœ¨ä½¿ç”¨å†…å­˜ä¼˜åŒ–æ¨¡å¼åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        if not os.path.exists(checkpoint_path):
            print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return 0, float('inf'), None
            
        # ç›´æ¥åŠ è½½åˆ°CPUï¼Œé¿å…GPUæ˜¾å­˜å ç”¨
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Š
        model = model.to('cpu')
        
        # ç›´æ¥åŠ è½½çŠ¶æ€å­—å…¸ï¼Œæ— éœ€é¢å¤–æ‹·è´
        model.load_state_dict(checkpoint['model_state_dict'])
        
        if optimizer is not None and load_optimizer and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        #if optimizer is not None and load_optimizer and 'optimizer_state_dict' in checkpoint:
            #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        epoch = checkpoint['epoch']
        train_loss = checkpoint['train_loss']
        val_loss = checkpoint.get('val_loss', None)
        
        # ç«‹å³æ¸…ç†æ£€æŸ¥ç‚¹æ•°æ®
        del checkpoint
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        
        print(f"âœ“ æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸï¼Epoch: {epoch}, Train Loss: {train_loss:.4f}" + 
              (f", Val Loss: {val_loss:.4f}" if val_loss else ""))
        
        return epoch, train_loss, val_loss
    else:
        # ä½¿ç”¨å…¶ä»–åŠ è½½å‡½æ•°
        if load_optimizer:
            epoch, train_loss, val_loss = load_checkpoint_memory_efficient(
                model, optimizer, checkpoint_path, device='cpu'
            )
        else:
            epoch, train_loss = load_model_only(
                model, checkpoint_path, device='cpu', strict=False
            )
            val_loss = None
        
        return epoch, train_loss, val_loss


def resume_training(model, optimizer, checkpoint_dir="/data/1024whs_checkpoint/Degradclean", memory_efficient=True, load_optimizer=True):
    """
    ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ - æ”¯æŒå†…å­˜ä¼˜åŒ–
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        optimizer: ä¼˜åŒ–å™¨å®ä¾‹
        checkpoint_dir: æ£€æŸ¥ç‚¹ç›®å½•
        memory_efficient: æ˜¯å¦ä½¿ç”¨å†…å­˜é«˜æ•ˆæ¨¡å¼
        load_optimizer: æ˜¯å¦åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
    
    Returns:
        start_epoch: æ¢å¤è®­ç»ƒçš„èµ·å§‹epoch
    """
    latest_checkpoint = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
    if os.path.exists(latest_checkpoint):
        print("ğŸ”„ å‘ç°æ£€æŸ¥ç‚¹ï¼Œæ¢å¤è®­ç»ƒ...")
        
        # å…ˆæŸ¥çœ‹æ£€æŸ¥ç‚¹ä¿¡æ¯
        info = get_checkpoint_info(latest_checkpoint)
        if info:
            print(f"ğŸ“‹ æ£€æŸ¥ç‚¹ä¿¡æ¯: Epoch {info['epoch']}, "
                  f"Train Loss: {info['train_loss']:.4f}, "
                  f"æ–‡ä»¶å¤§å°: {info['file_size_mb']:.1f}MB")
        
        # å†…å­˜é«˜æ•ˆåŠ è½½
        epoch, _, _ = load_checkpoint(model, optimizer, latest_checkpoint, 
                                    memory_efficient=memory_efficient, 
                                    load_optimizer=load_optimizer)
        
        # æ¸…ç†ç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        return 0  # ä¸‹ä¸€ä¸ªepoch
    else:
        print("ğŸ†• æœªæ‰¾åˆ°æœ€æ–°æ£€æŸ¥ç‚¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
        return 0


def check_data(d_dataset,c_dataset):
     if len(d_dataset) != len(c_dataset):
        print(f"è­¦å‘Š: é€€åŒ–æ•°é‡({len(d_dataset)})ä¸å¯è§å…‰å›¾åƒæ•°é‡({len(c_dataset)})ä¸ç›¸ç­‰")
        # å–è¾ƒå°çš„æ•°é‡ï¼Œç¡®ä¿é…å¯¹
        min_len = min(len(d_dataset), len(c_dataset))
        d_dataset.image_paths = d_dataset.image_paths[:min_len]
        c_dataset.image_paths = c_dataset.image_paths[:min_len]
        print(f"å·²è°ƒæ•´ä¸ºç›¸åŒæ•°é‡: {min_len}")
    
    # ç¡®ä¿æ–‡ä»¶åæ’åºä¸€è‡´
     d_dataset.image_paths.sort()
     c_dataset.image_paths.sort()
    
    # éªŒè¯æ–‡ä»¶åå¯¹åº”å…³ç³»ï¼ˆå‡è®¾æ–‡ä»¶åæ ¼å¼ç›¸åŒï¼Œåªæ˜¯æ‰©å±•åæˆ–å‰ç¼€ä¸åŒï¼‰
     d_names = [os.path.splitext(os.path.basename(path))[0] for path in d_dataset.image_paths]
     c_names = [os.path.splitext(os.path.basename(path))[0] for path in c_dataset.image_paths]

     if d_names != c_names:
        print("è­¦å‘Š: é€€åŒ–å’Œå¹²å‡€å›¾åƒæ–‡ä»¶åä¸å®Œå…¨å¯¹åº”")
        # æ‰¾åˆ°å…±åŒçš„æ–‡ä»¶å
        common_names = set(d_names) & set(c_names)
        print(f"å…±åŒæ–‡ä»¶æ•°é‡: {len(common_names)}")
        
        # é‡æ–°ç­›é€‰å¯¹åº”çš„æ–‡ä»¶
        d_filtered = []
        c_filtered = []
        for name in sorted(common_names):
            d_idx = d_names.index(name)
            c_idx = c_names.index(name)
            d_filtered.append(d_dataset.image_paths[d_idx])
            c_filtered.append(c_dataset.image_paths[c_idx])

        d_dataset.image_paths = d_filtered
        c_dataset.image_paths = c_filtered
        print(f"å·²ç­›é€‰å‡ºå¯¹åº”çš„å›¾åƒå¯¹: {len(d_dataset.image_paths)}")

     print(f"æœ€ç»ˆé…å¯¹æ•°é‡: é€€åŒ–å›¾åƒ{len(d_dataset)}, å¹²å‡€å›¾åƒ{len(c_dataset)}")

def main(d_data_dir, c_data_dir, project_name, batch_size, num_epochs=10, device_1="cuda:0", device_2="cuda:1", device_3="cuda:2", resume_from_checkpoint=True,i_block_num=2,v_block_num=2,i_expert_num=3,v_expert_num=3,i_topk_expert=2,v_topk_expert=2,i_alpha=1.0,v_alpha=1.0,f_block_num=3,mode="L", memory_efficient=True, load_optimizer_state=True, compress_checkpoints=True, save_optimizer_in_epoch_checkpoints=False):
    if mode=="L":
        transform = transforms.Compose([
            transforms.Resize((224,224)),  # è°ƒæ•´å›¾åƒå¤§å°
            transforms.ToTensor(),          # è½¬æ¢ä¸ºå¼ é‡ [0,1]
            transforms.Normalize(mean=[0.5], std=[0.5])  # å•é€šé“æ ‡å‡†åŒ–
        ])
    if mode=="RGB":
        transform = transforms.Compose([
            transforms.Resize((224,224)),  # è°ƒæ•´å›¾åƒå¤§å°
            transforms.ToTensor(),          # è½¬æ¢ä¸ºå¼ é‡ [0,1]
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGBæ ‡å‡†åŒ–
        ])
    
    d_dataset = ImageDataset(d_data_dir, transform=transform, convert=mode)
    c_dataset = ImageDataset(c_data_dir, transform=transform, convert=mode)
    
    # æ£€æŸ¥æ•°æ®é›†
    check_data(d_dataset, c_dataset)
    
    # åˆ›å»ºè”åˆæ•°æ®é›†
    dc_dataset = PairedDataset(d_dataset, c_dataset)
    
    print(f"è”åˆæ•°æ®é›†åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(dc_dataset)} å¯¹å›¾åƒ")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    train_loader = DataLoader(dc_dataset, batch_size=batch_size, shuffle=True, 
                             num_workers=2, pin_memory=False)  # å‡å°‘workerså’Œç¦ç”¨pin_memory
    print(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼Œæ‰¹æ¬¡å¤§å°:{batch_size}")
    
    # å†…å­˜ä¼˜åŒ–è®¾ç½®
    torch.backends.cudnn.benchmark = False  # ç¦ç”¨cudnn benchmarkä»¥èŠ‚çœå†…å­˜
    torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
    
    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = Degrad_restore_model(i_block_num=2,v_block_num=2,i_expert_num=3,v_expert_num=3,i_topk_expert=2,v_topk_expert=2,i_alpha=1.0,v_alpha=1.0,f_block_num=3,mode=mode)  # ä½ çš„æ¨¡å‹
    
    criterion = Loss()  # ä½ çš„æŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # é™ä½å­¦ä¹ ç‡
    
    # å‚æ•°æ£€æŸ¥
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # æƒé‡åˆå§‹åŒ–æ£€æŸ¥
    has_nan_weights = any(torch.isnan(p).any() for p in model.parameters())
    has_inf_weights = any(torch.isinf(p).any() for p in model.parameters())
    if has_nan_weights or has_inf_weights:
        print("âš ï¸  è­¦å‘Šï¼šæ¨¡å‹æƒé‡åŒ…å« NaN æˆ– Inf å€¼ï¼")
    else:
        print("âœ“ æ¨¡å‹æƒé‡åˆå§‹åŒ–æ­£å¸¸")
    
    # æ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = f"/data/1024whs_checkpoint/Degradclean/{project_name}"
    
    # æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    start_epoch = 0
    if resume_from_checkpoint:
        start_epoch = resume_training(
            model, optimizer, checkpoint_dir, 
            memory_efficient=memory_efficient, 
            load_optimizer=load_optimizer_state
        )
    
    # è°ƒæ•´è®­ç»ƒè½®æ•°
    remaining_epochs = max(0, num_epochs - start_epoch)
    if remaining_epochs == 0:
        print("è®­ç»ƒå·²å®Œæˆï¼")
        return
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œä» epoch {start_epoch + 1} åˆ° epoch {num_epochs}")
    
    # å¼€å§‹è®­ç»ƒ
    best_epoch, best_loss = train_model(
        model=model, 
        train_loader=train_loader, 
        criterion=criterion, 
        optimizer=optimizer, 
        device_1=device_1, 
        device_2=device_2,  
        project_name=project_name,
        num_epochs=remaining_epochs, 
        val_loader=None,  # å¦‚æœæœ‰éªŒè¯æ•°æ®ï¼Œåœ¨è¿™é‡Œä¼ å…¥
        checkpoint_dir=checkpoint_dir
    )
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æœ€ä½³æ¨¡å‹: Epoch {best_epoch}, Loss: {best_loss:.4f}")
    print(f"ğŸ’¾ æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: {checkpoint_dir}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼ˆç¤ºä¾‹ï¼‰
    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')
    if os.path.exists(best_model_path):
        print(f"âœ“ æœ€ä½³æ¨¡å‹è·¯å¾„: {best_model_path}")
        # è¿™é‡Œå¯ä»¥åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç†æˆ–æµ‹è¯•
        # load_checkpoint(model, None, best_model_path)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è®­ç»ƒé€€åŒ–æ¢å¤æ¨¡å‹')
    
    # æ·»åŠ é…ç½®æ–‡ä»¶é€‰é¡¹
    parser.add_argument('--config', type=str, help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--experiment', type=str, help='å®éªŒåç§°ï¼ˆå¯é€‰ï¼‰')
    
    # ä¿ç•™åŸæœ‰çš„å‘½ä»¤è¡Œå‚æ•°ä½œä¸ºå¤‡é€‰
    parser.add_argument('--d_data_dir', type=str, default="/data/1024whs_data/DeMMI-RF/Train/degrad/Stripe/DroneRGBT", help='é€€åŒ–å›¾åƒæ•°æ®ç›®å½•')
    parser.add_argument('--c_data_dir', type=str, default="/data/1024whs_data/DeMMI-RF/Train/infrared/Stripe/DroneRGBT", help='å¹²å‡€å›¾åƒæ•°æ®ç›®å½•')
    parser.add_argument('--project_name', type=str, default="Train_Degradclean_DroneRGBT_stripe", help='é¡¹ç›®åç§°')
    parser.add_argument('--batch_size', type=int, default=2, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_epochs', type=int, default=5, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--device_1', type=str, default="cuda:0", help='ç¬¬ä¸€ä¸ªGPUè®¾å¤‡')
    parser.add_argument('--device_2', type=str, default="cuda:1", help='ç¬¬äºŒä¸ªGPUè®¾å¤‡')
    parser.add_argument('--resume_from_checkpoint', default=True, action='store_true', help='æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    parser.add_argument('--i_block_num', type=int, default=2, help='çº¢å¤–åˆ†æ”¯å—æ•°é‡')
    parser.add_argument('--v_block_num', type=int, default=2, help='å¯è§å…‰åˆ†æ”¯å—æ•°é‡')
    parser.add_argument('--i_expert_num', type=int, default=3, help='çº¢å¤–ä¸“å®¶æ•°é‡')
    parser.add_argument('--v_expert_num', type=int, default=3, help='å¯è§å…‰ä¸“å®¶æ•°é‡')
    parser.add_argument('--i_topk_expert', type=int, default=2, help='çº¢å¤–topkä¸“å®¶')
    parser.add_argument('--v_topk_expert', type=int, default=2, help='å¯è§å…‰topkä¸“å®¶')
    parser.add_argument('--i_alpha', type=float, default=1.0, help='çº¢å¤–alphaå‚æ•°')
    parser.add_argument('--v_alpha', type=float, default=1.0, help='å¯è§å…‰alphaå‚æ•°')
    parser.add_argument('--f_block_num', type=int, default=3, help='èåˆå—æ•°é‡')
    parser.add_argument('--mode', type=str, default="L", choices=["L", "RGB"], help='å›¾åƒæ¨¡å¼')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶ï¼Œåˆ™ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
    if args.config:
        print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°: {args.config}")
        if args.experiment:
            print(f"ğŸ§ª ä½¿ç”¨å®éªŒé…ç½®: {args.experiment}")
        
        try:
            config = load_config(args.config, args.experiment)
            config_dic = config_to_args(config)
            
            # æ‰“å°é…ç½®ä¿¡æ¯
            print("ğŸ“‹ é…ç½®æ–‡ä»¶å†…å®¹:")
            for section, content in config.items():
                if section != 'experiments' and isinstance(content, dict):
                    print(f"  {section}:")
                    for key, value in content.items():
                        print(f"    {key}: {value}")
            
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
            exit(1)
        except yaml.YAMLError as e:
            print(f"âŒ é”™è¯¯: YAMLæ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            exit(1)
        except Exception as e:
            print(f"âŒ é”™è¯¯: åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            exit(1)
    else:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
        print("âŒ¨ï¸  ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°")
        config_dic = {
            "d_data_dir": args.d_data_dir,
            "c_data_dir": args.c_data_dir,
            "project_name": args.project_name,
            "batch_size": args.batch_size,
            "num_epochs": args.num_epochs,
            "device_1": args.device_1,
            "device_2": args.device_2,
            "device_3": getattr(args, 'device_3', 'cuda:2'),
            "resume_from_checkpoint": args.resume_from_checkpoint,
            "i_block_num": args.i_block_num,
            "v_block_num": args.v_block_num,
            "i_expert_num": args.i_expert_num,
            "v_expert_num": args.v_expert_num,
            "i_topk_expert": args.i_topk_expert,
            "v_topk_expert": args.v_topk_expert,
            "i_alpha": args.i_alpha,
            "v_alpha": args.v_alpha,
            "f_block_num": args.f_block_num,
            "mode": args.mode,
            "memory_efficient": getattr(args, 'memory_efficient', True),
            "load_optimizer_state": getattr(args, 'load_optimizer_state', True),
            "compress_checkpoints": getattr(args, 'compress_checkpoints', True),
            "save_optimizer_in_epoch_checkpoints": getattr(args, 'save_optimizer_in_epoch_checkpoints', False)
        }
    
    print("è®­ç»ƒé…ç½®:")
    for key, value in config_dic.items():
        print(f"  {key}: {value}")
    
    main(**config_dic)