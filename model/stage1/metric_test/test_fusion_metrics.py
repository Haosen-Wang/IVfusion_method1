"""
å›¾åƒèåˆæŒ‡æ ‡æµ‹è¯•è„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å„ç§èåˆè¯„ä¼°æŒ‡æ ‡
"""

import os
import sys
import numpy as np
import cv2
import torch
from PIL import Image
import matplotlib.pyplot as plt
import json
from typing import List, Dict

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(__file__))
from fusion_metrics import ImageFusionMetrics, test_fusion_metrics, batch_evaluate_fusion


def create_test_images():
    """åˆ›å»ºæµ‹è¯•å›¾åƒç”¨äºæ¼”ç¤º"""
    print("åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    test_dir = "test_fusion_images"
    os.makedirs(test_dir, exist_ok=True)
    os.makedirs(f"{test_dir}/source1", exist_ok=True)
    os.makedirs(f"{test_dir}/source2", exist_ok=True)
    os.makedirs(f"{test_dir}/fused", exist_ok=True)
    os.makedirs(f"{test_dir}/reference", exist_ok=True)
    
    # ç”Ÿæˆä¸åŒç±»å‹çš„æµ‹è¯•å›¾åƒ
    size = (256, 256)
    
    for i in range(3):
        # æºå›¾åƒ1 - é«˜é¢‘ç»†èŠ‚
        source1 = np.zeros(size, dtype=np.float32)
        source1[50:200, 50:200] = 0.8  # çŸ©å½¢åŒºåŸŸ
        source1 += np.random.normal(0, 0.1, size)  # æ·»åŠ å™ªå£°
        source1 = np.clip(source1, 0, 1)
        
        # æºå›¾åƒ2 - ä½é¢‘èƒŒæ™¯
        y, x = np.ogrid[:size[0], :size[1]]
        source2 = np.sin(x * 0.02) * np.cos(y * 0.02) * 0.5 + 0.5
        source2 = source2.astype(np.float32)
        
        # èåˆå›¾åƒ - ç®€å•åŠ æƒå¹³å‡
        fused = 0.6 * source1 + 0.4 * source2
        
        # å‚è€ƒå›¾åƒ - ç†æƒ³èåˆ
        reference = np.maximum(source1, source2)
        
        # ä¿å­˜å›¾åƒ
        cv2.imwrite(f"{test_dir}/source1/test_{i+1}.png", (source1 * 255).astype(np.uint8))
        cv2.imwrite(f"{test_dir}/source2/test_{i+1}.png", (source2 * 255).astype(np.uint8))
        cv2.imwrite(f"{test_dir}/fused/test_{i+1}.png", (fused * 255).astype(np.uint8))
        cv2.imwrite(f"{test_dir}/reference/test_{i+1}.png", (reference * 255).astype(np.uint8))
    
    print(f"æµ‹è¯•å›¾åƒå·²åˆ›å»ºåˆ°: {test_dir}")
    return test_dir


def test_single_image_metrics():
    """æµ‹è¯•å•å¼ å›¾åƒçš„æ‰€æœ‰æŒ‡æ ‡"""
    print("\n" + "="*60)
    print("å•å¼ å›¾åƒæŒ‡æ ‡æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_dir = create_test_images()
    
    # æµ‹è¯•ç¬¬ä¸€å¼ å›¾åƒ
    fused_path = f"{test_dir}/fused/test_1.png"
    source_paths = [
        f"{test_dir}/source1/test_1.png",
        f"{test_dir}/source2/test_1.png"
    ]
    reference_path = f"{test_dir}/reference/test_1.png"
    
    # è®¡ç®—æŒ‡æ ‡
    results = test_fusion_metrics(
        fused_path, 
        source_paths, 
        reference_path,
        save_results=True
    )
    
    return results


def test_batch_evaluation():
    """æµ‹è¯•æ‰¹é‡è¯„ä¼°åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æ‰¹é‡è¯„ä¼°æµ‹è¯•")
    print("="*60)
    
    test_dir = "test_fusion_images"
    
    # æ‰¹é‡è¯„ä¼°
    batch_evaluate_fusion(
        fused_dir=f"{test_dir}/fused",
        source_dirs=[f"{test_dir}/source1", f"{test_dir}/source2"],
        reference_dir=f"{test_dir}/reference",
        output_file="test_batch_results.csv"
    )


def test_torch_tensor_input():
    """æµ‹è¯•PyTorchå¼ é‡è¾“å…¥"""
    print("\n" + "="*60)
    print("PyTorchå¼ é‡è¾“å…¥æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºPyTorchå¼ é‡
    fused_tensor = torch.rand(1, 256, 256)  # (C, H, W)
    source1_tensor = torch.rand(1, 256, 256)
    source2_tensor = torch.rand(1, 256, 256)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ImageFusionMetrics()
    
    # è®¡ç®—æŒ‡æ ‡
    results = evaluator.compute_all_metrics(
        fused_tensor, 
        [source1_tensor, source2_tensor]
    )
    
    print("PyTorchå¼ é‡æµ‹è¯•ç»“æœ:")
    for metric, value in results.items():
        print(f"{metric:6s}: {value:.6f}")


def compare_fusion_methods():
    """æ¯”è¾ƒä¸åŒèåˆæ–¹æ³•çš„æ€§èƒ½"""
    print("\n" + "="*60)
    print("èåˆæ–¹æ³•æ€§èƒ½æ¯”è¾ƒ")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    size = (256, 256)
    source1 = np.random.rand(*size).astype(np.float32)
    source2 = np.random.rand(*size).astype(np.float32)
    
    # ä¸åŒèåˆæ–¹æ³•
    fusion_methods = {
        "Average": (source1 + source2) / 2,
        "Maximum": np.maximum(source1, source2),
        "Weighted_0.6_0.4": 0.6 * source1 + 0.4 * source2,
        "Weighted_0.3_0.7": 0.3 * source1 + 0.7 * source2,
    }
    
    evaluator = ImageFusionMetrics()
    comparison_results = {}
    
    for method_name, fused_img in fusion_methods.items():
        results = evaluator.compute_all_metrics(
            fused_img, 
            [source1, source2]
        )
        comparison_results[method_name] = results
        
        print(f"\n{method_name}:")
        for metric, value in results.items():
            print(f"  {metric:6s}: {value:.6f}")
    
    # ä¿å­˜æ¯”è¾ƒç»“æœ
    with open("fusion_methods_comparison.json", "w") as f:
        json.dump(comparison_results, f, indent=2)
    
    print(f"\næ¯”è¾ƒç»“æœå·²ä¿å­˜åˆ°: fusion_methods_comparison.json")
    
    return comparison_results


def analyze_metric_sensitivity():
    """åˆ†ææŒ‡æ ‡å¯¹ä¸åŒå›¾åƒç‰¹å¾çš„æ•æ„Ÿæ€§"""
    print("\n" + "="*60)
    print("æŒ‡æ ‡æ•æ„Ÿæ€§åˆ†æ")
    print("="*60)
    
    evaluator = ImageFusionMetrics()
    
    # æµ‹è¯•ä¸åŒç‰¹å¾çš„å›¾åƒ
    test_cases = {
        "High_Contrast": {
            "fused": np.random.rand(256, 256) * 0.8 + 0.1,
            "source1": np.random.rand(256, 256) * 0.5,
            "source2": np.random.rand(256, 256) * 0.5 + 0.5
        },
        "Low_Contrast": {
            "fused": np.random.rand(256, 256) * 0.2 + 0.4,
            "source1": np.random.rand(256, 256) * 0.1 + 0.45,
            "source2": np.random.rand(256, 256) * 0.1 + 0.45
        },
        "High_Detail": {
            "fused": np.random.rand(256, 256),
            "source1": np.random.rand(256, 256),
            "source2": np.random.rand(256, 256)
        },
        "Smooth": {
            "fused": np.ones((256, 256)) * 0.5 + np.random.rand(256, 256) * 0.1,
            "source1": np.ones((256, 256)) * 0.4 + np.random.rand(256, 256) * 0.05,
            "source2": np.ones((256, 256)) * 0.6 + np.random.rand(256, 256) * 0.05
        }
    }
    
    sensitivity_results = {}
    
    for case_name, images in test_cases.items():
        results = evaluator.compute_all_metrics(
            images["fused"].astype(np.float32),
            [images["source1"].astype(np.float32), images["source2"].astype(np.float32)]
        )
        sensitivity_results[case_name] = results
        
        print(f"\n{case_name}:")
        for metric, value in results.items():
            print(f"  {metric:6s}: {value:.6f}")
    
    # ä¿å­˜æ•æ„Ÿæ€§åˆ†æç»“æœ
    with open("metric_sensitivity_analysis.json", "w") as f:
        json.dump(sensitivity_results, f, indent=2)
    
    print(f"\næ•æ„Ÿæ€§åˆ†æç»“æœå·²ä¿å­˜åˆ°: metric_sensitivity_analysis.json")
    
    return sensitivity_results


def generate_detailed_report():
    """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ç”Ÿæˆè¯¦ç»†æµ‹è¯•æŠ¥å‘Š")
    print("="*60)
    
    report = {
        "test_timestamp": str(np.datetime64('now')),
        "single_image_test": test_single_image_metrics(),
        "torch_tensor_test": None,
        "fusion_methods_comparison": compare_fusion_methods(),
        "sensitivity_analysis": analyze_metric_sensitivity()
    }
    
    # PyTorchå¼ é‡æµ‹è¯•
    try:
        fused_tensor = torch.rand(1, 256, 256)
        source1_tensor = torch.rand(1, 256, 256)
        source2_tensor = torch.rand(1, 256, 256)
        
        evaluator = ImageFusionMetrics()
        torch_results = evaluator.compute_all_metrics(
            fused_tensor, [source1_tensor, source2_tensor]
        )
        report["torch_tensor_test"] = torch_results
        print("âœ“ PyTorchå¼ é‡æµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"âœ— PyTorchå¼ é‡æµ‹è¯•å¤±è´¥: {e}")
        report["torch_tensor_test"] = None
    
    # ä¿å­˜å®Œæ•´æŠ¥å‘Š
    with open("fusion_metrics_test_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nè¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: fusion_metrics_test_report.json")
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print("âœ“ å•å¼ å›¾åƒæŒ‡æ ‡æµ‹è¯• - å®Œæˆ")
    print("âœ“ æ‰¹é‡è¯„ä¼°æµ‹è¯• - å®Œæˆ")
    print("âœ“ èåˆæ–¹æ³•æ¯”è¾ƒ - å®Œæˆ")
    print("âœ“ æŒ‡æ ‡æ•æ„Ÿæ€§åˆ†æ - å®Œæˆ")
    print("âœ“ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ - å®Œæˆ")
    print("\næ‰€æœ‰æµ‹è¯•æ–‡ä»¶:")
    print("- test_fusion_images/          # æµ‹è¯•å›¾åƒç›®å½•")
    print("- test_batch_results.csv       # æ‰¹é‡è¯„ä¼°ç»“æœ")
    print("- fusion_methods_comparison.json # èåˆæ–¹æ³•æ¯”è¾ƒ")
    print("- metric_sensitivity_analysis.json # æ•æ„Ÿæ€§åˆ†æ")
    print("- fusion_metrics_test_report.json # å®Œæ•´æµ‹è¯•æŠ¥å‘Š")


if __name__ == "__main__":
    print("å›¾åƒèåˆæŒ‡æ ‡æµ‹è¯•ç³»ç»Ÿ")
    print("Author: Assistant")
    print("Date: 2025-09-04")
    print("="*60)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import pandas as pd
        print("âœ“ ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError:
        print("âœ— ç¼ºå°‘pandasï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        print("å®‰è£…å‘½ä»¤: pip install pandas")
    
    # è¿è¡Œå®Œæ•´æµ‹è¯•
    try:
        generate_detailed_report()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
