import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
import torch
from torch.utils.data import Dataset,DataLoader
from tqdm import tqdm
import wandb
import torch.nn as nn
from model import IV_fusion_model
from loss import Loss
from data_process.dataset import ImageDataset
from PIL import Image
import math
import torchvision.transforms as transforms

class PairedDataset(Dataset):
        def __init__(self, i_dataset, v_dataset):
            assert len(i_dataset) == len(v_dataset), "ä¸¤ä¸ªæ•°æ®é›†é•¿åº¦å¿…é¡»ç›¸ç­‰"
            self.i_dataset = i_dataset
            self.v_dataset = v_dataset
        
        def __len__(self):
            return len(self.i_dataset)
        
        def __getitem__(self, idx):
            i_image= self.i_dataset[idx][0]
            v_image = self.v_dataset[idx][0]
            return i_image, v_image
def train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, device_3, val_loader, pbar):
    model.train()
    running_loss = 0.0
    epoch_loss = 0.0
    
    # æ¸…ç†GPUç¼“å­˜
    torch.cuda.empty_cache()
    
    for batch_idx, (i_image, v_image) in enumerate(pbar):
        try:
            output, l, g, mu_l, sigma2_l, mu_g, sigma2_g = model(i_image, v_image, device_1, device_2, device_3)
            
            # è®¡ç®—æŸå¤±
            criterion=criterion.to(device_3)
            # å°†æ¨¡å‹è¾“å‡ºç§»åŠ¨åˆ°device_3
            i_image=i_image.to(device_3)
            v_image=v_image.to(device_3)
            output = output.to(device_3)
            l = l.to(device_3)
            g = g.to(device_3)
            mu_l = mu_l.to(device_3)
            sigma2_l = sigma2_l.to(device_3)
            mu_g = mu_g.to(device_3)
            sigma2_g = sigma2_g.to(device_3)
            torch.cuda.empty_cache()
            loss_all= criterion(output, i_image, v_image, l, g, mu_l, sigma2_l, mu_g, sigma2_g)
            del i_image,v_image,output,l,g,mu_l,sigma2_l,mu_g,sigma2_g
            loss=loss_all["total_loss"]
            
            # æ£€æµ‹ NaN å’Œ Inf
            if torch.isnan(loss) or torch.isinf(loss):
                print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} æ£€æµ‹åˆ° NaN/Inf æŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡...")
                print(f"æŸå¤±è¯¦æƒ…: {loss_all}")
                torch.cuda.empty_cache()
                continue

            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            optimizer.zero_grad()
            wandb.log(loss_all)
            torch.cuda.empty_cache()
            
            # ç»Ÿè®¡æŸå¤±
            running_loss += loss.item()
            epoch_loss += loss.item()

                
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} å†…å­˜ä¸è¶³ï¼Œè·³è¿‡...")
                torch.cuda.empty_cache()
                continue
            else:
                raise e
                
    return epoch_loss
def train_model(model, train_loader, criterion, optimizer, device_1, device_2, device_3, project_name, num_epochs=10, val_loader=None, checkpoint_dir="./checkpoints"):
    """
    è®­ç»ƒå‡½æ•°ï¼Œé›†æˆwandbç›‘æ§å’Œæ£€æŸ¥ç‚¹ä¿å­˜
    
    Args:
        model: è®­ç»ƒæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        device_1, device_2, device_3: è®¾å¤‡
        num_epochs: è®­ç»ƒè½®æ•°
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        project_name: wandbé¡¹ç›®åç§°
        checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
    """
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # åˆå§‹åŒ–wandb
    wandb.init(project=project_name)
    
    # åˆå§‹åŒ–æœ€ä½³æ€§èƒ½æŒ‡æ ‡
    best_val_loss = float('inf')
    best_train_loss = float('inf') 
    best_epoch = 0
    
    model.train()
    
    for epoch in range(num_epochs):
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - éšç€è®­ç»ƒå‡å°å­¦ä¹ ç‡
        if epoch == 0:
            # åœ¨ç¬¬ä¸€ä¸ªepochåˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
            #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)
            # æˆ–è€…ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
            # æˆ–è€…ä½¿ç”¨æŒ‡æ•°è¡°å‡
            # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)

        # åœ¨æ¯ä¸ªepochç»“æŸåæ›´æ–°å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']
        print(f'å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}')
        
        # åœ¨æ¯ä¸ªepochç»“æŸåæ›´æ–°å­¦ä¹ ç‡
        epoch_loss = train_epoch_model(model, train_loader, criterion, optimizer, device_1, device_2, device_3, val_loader, pbar)
        scheduler.step()
        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_loss = epoch_loss / len(train_loader)

        # éªŒè¯é˜¶æ®µ
        val_metrics = {}
        val_loss = None
        if val_loader is not None:
            val_loss, val_acc = validate_model(model, val_loader, criterion, device_1, device_2, device_3)
            val_metrics = {"val_loss": val_loss}
        
        # è®°å½•epochæŒ‡æ ‡åˆ°wandb
        wandb.log({
            "epoch": epoch + 1,
            "train_loss": avg_loss,
            **val_metrics
        })
        
        # ä¿å­˜å½“å‰epochæ£€æŸ¥ç‚¹
        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': avg_loss,
            'val_loss': val_loss,
            **val_metrics
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_checkpoint_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, latest_checkpoint_path)
        
        # ä¿å­˜æ¯ä¸ªepochçš„æ£€æŸ¥ç‚¹
        epoch_checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')
        torch.save(checkpoint, epoch_checkpoint_path)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        is_best = False
        current_metric = val_loss if val_loss is not None else avg_loss
        best_metric = best_val_loss if val_loss is not None else best_train_loss
        
        if current_metric < best_metric:
            is_best = True
            if val_loss is not None:
                best_val_loss = val_loss
            else:
                best_train_loss = avg_loss
            best_epoch = epoch + 1
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            best_checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')
            torch.save(checkpoint, best_checkpoint_path)
            print(f"âœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ (Epoch {epoch+1})")
        
        # æ‰“å°epochæŸå¤±
        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_loss:.4f}' + 
              (f', Val Loss: {val_metrics.get("val_loss", 0):.4f}, Val Acc: {val_metrics.get("val_accuracy", 0):.4f}' if val_metrics else '') +
              (f' {"ğŸ†" if is_best else ""}'))
    
    print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹æ¥è‡ª Epoch {best_epoch}")
    print(f"æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„: {checkpoint_dir}")
    return best_epoch, best_val_loss if val_loader else best_train_loss

def validate_model(model, val_loader, criterion, device_1, device_2, device_3):
    """
    éªŒè¯å‡½æ•°
    """
    model.eval()
    val_loss = 0.0
    
    with torch.no_grad():
        for i,v in tqdm(val_loader, desc='Validating'):
            output,l, g, mu_l, sigma2_l, mu_g, sigma2_g= model(i,v, device_1, device_2, device_3)
            loss_all= criterion(output, i,v, l, g, mu_l, sigma2_l, mu_g, sigma2_g)
            val_loss=loss_all["total_loss"]
            
    model.train()
    return val_loss / len(val_loader)


def load_checkpoint(model, optimizer, checkpoint_path):
    """
    åŠ è½½æ£€æŸ¥ç‚¹
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        optimizer: ä¼˜åŒ–å™¨å®ä¾‹
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
    
    Returns:
        epoch: æ£€æŸ¥ç‚¹å¯¹åº”çš„epoch
        loss: æ£€æŸ¥ç‚¹å¯¹åº”çš„æŸå¤±
    """
    if os.path.exists(checkpoint_path):
        print(f"æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path)
        
        model.load_state_dict(checkpoint['model_state_dict'])
        if optimizer is not None:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        epoch = checkpoint['epoch']
        train_loss = checkpoint['train_loss']
        val_loss = checkpoint.get('val_loss', None)
        
        print(f"âœ“ æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸï¼Epoch: {epoch}, Train Loss: {train_loss:.4f}" + 
              (f", Val Loss: {val_loss:.4f}" if val_loss else ""))
        
        return epoch, train_loss, val_loss
    else:
        print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return 0, None, None


def resume_training(model, optimizer, checkpoint_dir="/data/1024whs_checkpoint/iv_fusion"):
    """
    ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        optimizer: ä¼˜åŒ–å™¨å®ä¾‹
        checkpoint_dir: æ£€æŸ¥ç‚¹ç›®å½•
    
    Returns:
        start_epoch: æ¢å¤è®­ç»ƒçš„èµ·å§‹epoch
    """
    latest_checkpoint = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
    if os.path.exists(latest_checkpoint):
        epoch, _, _ = load_checkpoint(model, optimizer, latest_checkpoint)
        return epoch
    else:
        print("æœªæ‰¾åˆ°æœ€æ–°æ£€æŸ¥ç‚¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
        return 0


def check_data(i_dataset,v_dataset):
     if len(i_dataset) != len(v_dataset):
        print(f"è­¦å‘Š: çº¢å¤–å›¾åƒæ•°é‡({len(i_dataset)})ä¸å¯è§å…‰å›¾åƒæ•°é‡({len(v_dataset)})ä¸ç›¸ç­‰")
        # å–è¾ƒå°çš„æ•°é‡ï¼Œç¡®ä¿é…å¯¹
        min_len = min(len(i_dataset), len(v_dataset))
        i_dataset.image_paths = i_dataset.image_paths[:min_len]
        v_dataset.image_paths = v_dataset.image_paths[:min_len]
        print(f"å·²è°ƒæ•´ä¸ºç›¸åŒæ•°é‡: {min_len}")
    
    # ç¡®ä¿æ–‡ä»¶åæ’åºä¸€è‡´
     i_dataset.image_paths.sort()
     v_dataset.image_paths.sort()
    
    # éªŒè¯æ–‡ä»¶åå¯¹åº”å…³ç³»ï¼ˆå‡è®¾æ–‡ä»¶åæ ¼å¼ç›¸åŒï¼Œåªæ˜¯æ‰©å±•åæˆ–å‰ç¼€ä¸åŒï¼‰
     i_names = [os.path.splitext(os.path.basename(path))[0] for path in i_dataset.image_paths]
     v_names = [os.path.splitext(os.path.basename(path))[0] for path in v_dataset.image_paths]
    
     if i_names != v_names:
        print("è­¦å‘Š: çº¢å¤–å’Œå¯è§å…‰å›¾åƒæ–‡ä»¶åä¸å®Œå…¨å¯¹åº”")
        # æ‰¾åˆ°å…±åŒçš„æ–‡ä»¶å
        common_names = set(i_names) & set(v_names)
        print(f"å…±åŒæ–‡ä»¶æ•°é‡: {len(common_names)}")
        
        # é‡æ–°ç­›é€‰å¯¹åº”çš„æ–‡ä»¶
        i_filtered = []
        v_filtered = []
        for name in sorted(common_names):
            i_idx = i_names.index(name)
            v_idx = v_names.index(name)
            i_filtered.append(i_dataset.image_paths[i_idx])
            v_filtered.append(v_dataset.image_paths[v_idx])
        
        i_dataset.image_paths = i_filtered
        v_dataset.image_paths = v_filtered
        print(f"å·²ç­›é€‰å‡ºå¯¹åº”çš„å›¾åƒå¯¹: {len(i_dataset.image_paths)}")
    
     print(f"æœ€ç»ˆé…å¯¹æ•°é‡: çº¢å¤–å›¾åƒ{len(i_dataset)}, å¯è§å…‰å›¾åƒ{len(v_dataset)}")

def main(i_data_dir, v_data_dir, project_name, batch_size, num_epochs=10, device_1="cuda:0", device_2="cuda:1", device_3="cuda:2", resume_from_checkpoint=True,i_block_num=2,v_block_num=2,i_expert_num=3,v_expert_num=3,i_topk_expert=2,v_topk_expert=2,i_alpha=1.0,v_alpha=1.0,f_block_num=3):
    # ä¸ºçº¢å¤–å›¾åƒï¼ˆå•é€šé“ï¼‰åˆ›å»ºå˜æ¢
    transform_i = transforms.Compose([
        transforms.Resize((224,224)),  # è°ƒæ•´å›¾åƒå¤§å°
        transforms.ToTensor(),          # è½¬æ¢ä¸ºå¼ é‡ [0,1]
        transforms.Normalize(mean=[0.5], std=[0.5])  # å•é€šé“æ ‡å‡†åŒ–
    ])
    
    # ä¸ºå¯è§å…‰å›¾åƒï¼ˆ3é€šé“ï¼‰åˆ›å»ºå˜æ¢
    transform_v = transforms.Compose([
        transforms.Resize((224,224)),  # è°ƒæ•´å›¾åƒå¤§å°
        transforms.ToTensor(),          # è½¬æ¢ä¸ºå¼ é‡ [0,1]
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGBæ ‡å‡†åŒ–
    ])
    
    i_dataset = ImageDataset(i_data_dir, transform=transform_i, convert="L")
    v_dataset = ImageDataset(v_data_dir, transform=transform_v, convert="RGB")
    
    # æ£€æŸ¥æ•°æ®é›†
    check_data(i_dataset, v_dataset)
    
    # åˆ›å»ºè”åˆæ•°æ®é›†
    iv_dataset = PairedDataset(i_dataset, v_dataset)
    
    print(f"è”åˆæ•°æ®é›†åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(iv_dataset)} å¯¹å›¾åƒ")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    train_loader = DataLoader(iv_dataset, batch_size=batch_size, shuffle=True, 
                             num_workers=2, pin_memory=False)  # å‡å°‘workerså’Œç¦ç”¨pin_memory
    print(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼Œæ‰¹æ¬¡å¤§å°:{batch_size}")
    
    # å†…å­˜ä¼˜åŒ–è®¾ç½®
    torch.backends.cudnn.benchmark = False  # ç¦ç”¨cudnn benchmarkä»¥èŠ‚çœå†…å­˜
    torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
    
    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = IV_fusion_model(i_block_num=2,v_block_num=2,i_expert_num=3,v_expert_num=3,i_topk_expert=2,v_topk_expert=2,i_alpha=1.0,v_alpha=1.0,f_block_num=3)  # ä½ çš„æ¨¡å‹
    
    criterion = Loss()  # ä½ çš„æŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # é™ä½å­¦ä¹ ç‡
    
    # å‚æ•°æ£€æŸ¥
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # æƒé‡åˆå§‹åŒ–æ£€æŸ¥
    has_nan_weights = any(torch.isnan(p).any() for p in model.parameters())
    has_inf_weights = any(torch.isinf(p).any() for p in model.parameters())
    if has_nan_weights or has_inf_weights:
        print("âš ï¸  è­¦å‘Šï¼šæ¨¡å‹æƒé‡åŒ…å« NaN æˆ– Inf å€¼ï¼")
    else:
        print("âœ“ æ¨¡å‹æƒé‡åˆå§‹åŒ–æ­£å¸¸")
    
    # æ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = f"/data/1024whs_checkpoint/iv_fusion/{project_name}"
    
    # æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    start_epoch = 0
    if resume_from_checkpoint:
        start_epoch = resume_training(model, optimizer, checkpoint_dir)
    
    # è°ƒæ•´è®­ç»ƒè½®æ•°
    remaining_epochs = max(0, num_epochs - start_epoch)
    if remaining_epochs == 0:
        print("è®­ç»ƒå·²å®Œæˆï¼")
        return
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œä» epoch {start_epoch + 1} åˆ° epoch {num_epochs}")
    
    # å¼€å§‹è®­ç»ƒ
    best_epoch, best_loss = train_model(
        model=model, 
        train_loader=train_loader, 
        criterion=criterion, 
        optimizer=optimizer, 
        device_1=device_1, 
        device_2=device_2, 
        device_3=device_3, 
        project_name=project_name,
        num_epochs=remaining_epochs, 
        val_loader=None,  # å¦‚æœæœ‰éªŒè¯æ•°æ®ï¼Œåœ¨è¿™é‡Œä¼ å…¥
        checkpoint_dir=checkpoint_dir
    )
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æœ€ä½³æ¨¡å‹: Epoch {best_epoch}, Loss: {best_loss:.4f}")
    print(f"ğŸ’¾ æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: {checkpoint_dir}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼ˆç¤ºä¾‹ï¼‰
    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')
    if os.path.exists(best_model_path):
        print(f"âœ“ æœ€ä½³æ¨¡å‹è·¯å¾„: {best_model_path}")
        # è¿™é‡Œå¯ä»¥åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç†æˆ–æµ‹è¯•
        # load_checkpoint(model, None, best_model_path)

if __name__ == "__main__":
    config_dic = {
        "i_data_dir": "/data/1024whs_data/DeMMI-RF/Train_fusion/DroneVehicle/infrared",
        "v_data_dir": "/data/1024whs_data/DeMMI-RF/Train_fusion/DroneVehicle/visible",
        "project_name": "Train_IVfusion_DroneVehicle",
        "batch_size": 2,  # å‡å°æ‰¹æ¬¡å¤§å°ä»2åˆ°1
        "num_epochs": 5,
        "device_1": "cuda:0", 
        "device_2": "cuda:1",
        "device_3": "cuda:2",
        "resume_from_checkpoint": False  # è®¾ç½®ä¸ºTrueæ¥ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    }
    main(**config_dic)